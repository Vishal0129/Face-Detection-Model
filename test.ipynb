{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import socket\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_faces_dir = 'train_images'\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for person_name in os.listdir(known_faces_dir):\n",
    "    person_dir = os.path.join(known_faces_dir, person_name)\n",
    "    if os.path.isdir(person_dir):\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            # image = face_recognition.load_image_file(image_path)\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.resize(image, (0, 0), fx=0.25, fy=0.25)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "            if not face_encodings:\n",
    "                print(\"No face detected in\", image_path)\n",
    "                continue\n",
    "            face_encoding = face_encodings[0]\n",
    "            known_face_encodings.append(face_encoding)\n",
    "            known_face_names.append(person_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['danny', 'keanu', 'pavan', 'vinay', 'vishal']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_face_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('face recognisation.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv2.imread('train_images/keanu/keanu.jpeg')\n",
    "# # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.resize(image, (224,224))\n",
    "# image = image / 255.\n",
    "# image = image.reshape(1,224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# pred = classifier.predict(image)\n",
    "# end = time.time()\n",
    "# print(\"Time taken in prediction: \", end - start)\n",
    "# print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# known_face_names[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691495570.9497285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(imager, q:queue.Queue, id:int, encounter_time:str):\n",
    "    start = time.time()\n",
    "    imager = cv2.resize(imager, (640, 480), fx=0.25, fy=0.25)\n",
    "    face_locations = face_recognition.face_locations(imager, model=\"hog\")\n",
    "    face_encodings = face_recognition.face_encodings(imager, face_locations)\n",
    "    for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.6)        \n",
    "        name = \"Person\"\n",
    "        if True in matches:\n",
    "            match_index = matches.index(True)\n",
    "            name = known_face_names[match_index]\n",
    "        else:\n",
    "            return\n",
    "        top, right, bottom, left = face_location\n",
    "        cv2.rectangle(imager, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(imager, name, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        \n",
    "    end = time.time()\n",
    "    cv2.putText(imager, f\"Time: {encounter_time}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    # cv2.imshow(\"Frame\", imager)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    # return imager\n",
    "    q.put((id, encounter_time, imager))\n",
    "    q.task_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = '192.168.0.106'\n",
    "PORT = 8090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_frames(q:queue.Queue):\n",
    "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server.bind((HOST, PORT))\n",
    "    server.listen(1)\n",
    "    print('Server started')\n",
    "    conn, addr = server.accept()\n",
    "    print('Connected by', addr)\n",
    "    while True:\n",
    "        if not q.empty():\n",
    "            frame = q.get()\n",
    "            # q.task_done()\n",
    "            frame_data = cv2.imencode('.jpg', frame)[1].tobytes()\n",
    "            frame_size = len(frame_data)\n",
    "            conn.sendall(frame_size.to_bytes(4, byteorder='big'))\n",
    "            conn.sendall(frame_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames(q):\n",
    "    while True:\n",
    "        if not q.empty():\n",
    "            frame = q.get()\n",
    "            cv2.imshow('frame', frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://192.168.0.103:8080/shot.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 640\n",
    "height = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_balancer(q:queue.Queue, queues:list[queue.Queue]):\n",
    "    # i = 0\n",
    "    while True:\n",
    "        # if i==4:\n",
    "            # return\n",
    "        # i = 0\n",
    "        for i in range(4):\n",
    "            try:\n",
    "                frame = q.get(block=False)\n",
    "                threading.Thread(target=recognize_faces, args=(frame,queues[i], i, datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")[:-3])).start()\n",
    "            except:\n",
    "                continue\n",
    "                # i += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frames_from_load_balancer(qs:list[queue.Queue]):\n",
    "    while True:\n",
    "        for q in qs:\n",
    "            try:\n",
    "                id, frame = q.get()\n",
    "                cv2.imshow('frame', frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            except:\n",
    "                pass\n",
    "        # time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encounters(qs:list[queue.Queue], final_frames:queue.Queue):\n",
    "    # i = 0\n",
    "    while True:\n",
    "        # if i==4:\n",
    "            # break\n",
    "        # i = 0\n",
    "        for q in qs:\n",
    "            try:\n",
    "                id, encounter_time, frame = q.get(block=False)\n",
    "                filename = 'encounters/' + str(id) + '/' + encounter_time +'.jpg'\n",
    "                # cv2.imshow('Video', frame)\n",
    "                # final_frames.put((id, encounter_time, frame))\n",
    "                cv2.imwrite(filename, frame)\n",
    "                # print(f'encounter {id} at {encounter_time} {type(frame)}')\n",
    "                # while cv2.waitKey(1) & 0xFF != ord('q'):\n",
    "                    # continue\n",
    "            except:\n",
    "                # i += 1\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream thread...\n",
      "[INFO] starting load balancer thread...\n",
      "[INFO] starting recognition thread...\n",
      "Server started\n",
      "[INFO] starting encounters thread...\n",
      "FPS: 5.91192784195273e-10\n",
      "FPS: 1.6395239705344875\n",
      "Connected by ('192.168.0.100', 37082)\n",
      "FPS: 1.0028992063706503\n",
      "FPS: 0.8774184262923621\n",
      "FPS: 0.9452146511624239\n",
      "FPS: 1.6070481232731904\n",
      "FPS: 1.089949105612675\n",
      "FPS: 1.4221807496661814\n",
      "FPS: 1.1054523526321907\n",
      "FPS: 0.7768166125212502\n",
      "FPS: 0.6659069252158484\n",
      "FPS: 0.860974411166156\n",
      "FPS: 0.750521157472405\n",
      "FPS: 0.5096191231589916\n",
      "FPS: 1.0195704939113397\n",
      "FPS: 0.6400606502782933\n",
      "FPS: 1.2355302615222374\n",
      "FPS: 1.6007022123505414\n",
      "FPS: 1.4557863835181106\n",
      "FPS: 1.5239363103285526\n",
      "FPS: 1.6125978051958487\n",
      "FPS: 1.1234256373719531\n",
      "FPS: 0.9010958886451671\n",
      "FPS: 1.089010129344982\n",
      "FPS: 0.9200256465431675\n",
      "FPS: 1.3876807758273868\n",
      "FPS: 1.3061057731981236\n",
      "FPS: 1.2071054621160688\n",
      "FPS: 1.5025931645922426\n",
      "FPS: 0.9440230834501836\n",
      "FPS: 1.01324515470074\n",
      "FPS: 1.1812744672821391\n",
      "FPS: 0.8277401116006453\n",
      "FPS: 1.2442203124860947\n",
      "FPS: 1.0134108952862895\n",
      "FPS: 1.0980609397976877\n",
      "FPS: 1.4462842946082057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\saivishal radham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\saivishal radham\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\saivishal radham\\AppData\\Local\\Temp\\ipykernel_8084\\1673903670.py\", line 14, in send_frames\n",
      "ConnectionAbortedError: [WinError 10053] An established connection was aborted by the software in your host machine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 0.539960210108342\n",
      "FPS: 1.050963526391079\n",
      "FPS: 1.6844032909746383\n",
      "FPS: 1.143307298672971\n",
      "FPS: 1.5975501435938846\n",
      "FPS: 0.9670596416282314\n",
      "FPS: 1.2038891354153691\n",
      "FPS: 1.2564680648379203\n",
      "FPS: 1.0845959746149498\n",
      "FPS: 1.7732313890785487\n",
      "FPS: 1.4266655555309897\n",
      "FPS: 1.4994324805586607\n",
      "FPS: 2.4833810849232276\n",
      "FPS: 1.6571818255810187\n",
      "FPS: 1.0991100579100446\n",
      "FPS: 1.773131688394481\n",
      "FPS: 1.6763436455233798\n",
      "FPS: 1.4579304241491418\n",
      "FPS: 1.9494871231160158\n",
      "FPS: 1.305294055771913\n",
      "FPS: 1.8308318724988302\n",
      "FPS: 2.129852693326996\n",
      "FPS: 2.048563154812578\n",
      "FPS: 1.4158924944907747\n"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "queues = [queue.Queue() for _ in range(4)]\n",
    "q = queue.Queue() \n",
    "final_frames = queue.Queue()\n",
    "print(\"[INFO] starting video stream thread...\")\n",
    "threading.Thread(target=send_frames, args=(final_frames,)).start()\n",
    "print(\"[INFO] starting load balancer thread...\")\n",
    "print(\"[INFO] starting recognition thread...\")\n",
    "threading.Thread(target=load_balancer, args=(q,queues)).start()\n",
    "print(\"[INFO] starting encounters thread...\")\n",
    "threading.Thread(target=encounters, args=(queues,final_frames)).start()\n",
    "end = 0\n",
    "i=0\n",
    "while i<120:\n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img = cv2.imdecode(img_arr, -1)\n",
    "    img = imutils.resize(img, width=width, height=height)\n",
    "    \n",
    "    # ret, img = cam.read()\n",
    "    # print(type(img))\n",
    "    fps = 1 / (time.time() - end)   \n",
    "    print('FPS:', fps)\n",
    "    # img = cv2.resize(img, (height, width), fx=0.25, fy=0.25)\n",
    "    end = time.time()\n",
    "    q.put(img)\n",
    "    final_frames.put(img)\n",
    "    cv2.imshow('Camera', img)\n",
    "    cv2.imwrite('test_images/'+str(i)+'.jpg', img)\n",
    "    # cv2.imwrite('encounters/test'+str(i)+'.jpg', img)\n",
    "    # threading.Thread(target=recognize_faces, args=(img,q)).start()\n",
    "    # cv2.imshow('Camera', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    i+=1\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_video(camera):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_balancer(q, queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter 0 at 20230808_154034_662 <class 'numpy.ndarray'>\n",
      "encounter 1 at 20230808_154034_738 <class 'numpy.ndarray'>\n",
      "encounter 2 at 20230808_154034_608 <class 'numpy.ndarray'>\n",
      "encounter 3 at 20230808_154034_571 <class 'numpy.ndarray'>\n",
      "encounter 0 at 20230808_154034_565 <class 'numpy.ndarray'>\n",
      "encounter 1 at 20230808_154034_566 <class 'numpy.ndarray'>\n",
      "encounter 2 at 20230808_154034_567 <class 'numpy.ndarray'>\n",
      "encounter 3 at 20230808_154034_630 <class 'numpy.ndarray'>\n",
      "encounter 0 at 20230808_154034_573 <class 'numpy.ndarray'>\n",
      "encounter 1 at 20230808_154034_575 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "encounters(queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.qsize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(queues[i].qsize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    frame = q.get()\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threading.Thread(target=send_frames, args=(q,)).start()\n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # img_resp = requests.get(url)\n",
    "    # img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    # img = cv2.imdecode(img_arr, -1)      \n",
    "    ret, img = cam.read()\n",
    "    img = imutils.resize(img, width=width, height=height)\n",
    "    # img = cv2.resize(img, (width, height), fx=0.5, fy=0.5)\n",
    "    threading.Thread(target=recognize_faces, args=(img,q)).start()\n",
    "    cv2.imshow('Camera', img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import websocket\n",
    "\n",
    "def on_message(ws, message):\n",
    "    frame_base64 = message\n",
    "    image_data = base64.b64decode(frame_base64)\n",
    "    img = Image.open(BytesIO(image_data))\n",
    "    cv2.imshow('frame', cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR))\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        ws.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ws_url = 'ws://192.168.0.100:8000/ws/video'\n",
    "    ws = websocket.WebSocketApp(ws_url, on_message=on_message)\n",
    "    ws.run_forever()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facerecog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
